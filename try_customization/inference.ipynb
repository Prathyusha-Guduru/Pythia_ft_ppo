{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6171ea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cluster/piti/miniconda/envs/loading_models/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ecf7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e860b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_policy_id = \"cleanrl/EleutherAI_pythia-1b-deduped__sft__tldr\"\n",
    "reward_model_id = \"cleanrl/EleutherAI_pythia-1b-deduped__reward__tldr\"\n",
    "trained_value_model_id = \"Prathyusha101/pythia_1b_100_epochs_0.005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ebb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_model_id = AutoModelForSequenceClassification.from_pretrained(reward_model_id)\n",
    "trained_value_model_id = AutoModelForSequenceClassification.from_pretrained(trained_value_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af99aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_policy_id)\n",
    "tokenizer.context_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0516740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_true_indices(bools: torch.Tensor, dtype=torch.long):\n",
    "    \"\"\"\n",
    "    Takes an N-dimensional bool tensor and returns an (N-1)-dimensional tensor of integers giving\n",
    "    the position of the first True in each \"row\".\n",
    "\n",
    "    Returns the length of the rows (bools.size(-1)) if no element is True in a given row.\n",
    "\n",
    "    Args:\n",
    "        bools (`torch.Tensor`):\n",
    "            An N-dimensional boolean tensor.\n",
    "        dtype (`torch.dtype`, optional):\n",
    "            The desired data type of the output tensor. Defaults to `torch.long`.\n",
    "\n",
    "    Returns:\n",
    "        `torch.Tensor`:\n",
    "            An (N-1)-dimensional tensor of integers indicating the position of the first True\n",
    "            in each row. If no True value is found in a row, returns the length of the row.\n",
    "    \"\"\"\n",
    "    row_len = bools.size(-1)\n",
    "    zero_or_index = row_len * (~bools).type(dtype) + torch.arange(row_len, dtype=dtype, device=bools.device)\n",
    "    return torch.min(zero_or_index, dim=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c683a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(\n",
    "    model: torch.nn.Module, query_responses: torch.Tensor, pad_token_id: int, context_length: int\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Computes the reward logits and the rewards for a given model and query responses.\n",
    "\n",
    "    Args:\n",
    "        model (`torch.nn.Module`):\n",
    "            The model used to compute the reward logits.\n",
    "        query_responses (`torch.Tensor`):\n",
    "            The tensor containing the query responses.\n",
    "        pad_token_id (`int`):\n",
    "            The token ID representing the pad token.\n",
    "        context_length (`int`):\n",
    "            The length of the context in the query responses.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - `reward_logits` (`torch.Tensor`):\n",
    "                The logits for the reward model.\n",
    "            - `final_rewards` (`torch.Tensor`):\n",
    "                The final rewards for each query response.\n",
    "            - `sequence_lengths` (`torch.Tensor`):\n",
    "                The lengths of the sequences in the query responses.\n",
    "    \"\"\"\n",
    "    attention_mask = query_responses != pad_token_id\n",
    "    position_ids = attention_mask.cumsum(1) - attention_mask.long()  # exclusive cumsum\n",
    "    lm_backbone = getattr(model, model.base_model_prefix)\n",
    "    input_ids = torch.masked_fill(query_responses, ~attention_mask, 0)\n",
    "    output = lm_backbone(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        position_ids=position_ids,\n",
    "        return_dict=True,\n",
    "        output_hidden_states=True,\n",
    "        use_cache=False,  # otherwise mistral-based RM would error out\n",
    "    )\n",
    "    reward_logits = model.score(output.hidden_states[-1])\n",
    "    sequence_lengths = first_true_indices(query_responses[:, context_length:] == pad_token_id) - 1 + context_length\n",
    "    # https://github.com/huggingface/transformers/blob/dc68a39c8111217683bf49a4912d0c9018bab33d/src/transformers/models/gpt2/modeling_gpt2.py#L1454\n",
    "    return (\n",
    "        reward_logits,\n",
    "        reward_logits[\n",
    "            torch.arange(reward_logits.size(0), device=reward_logits.device),\n",
    "            sequence_lengths,\n",
    "        ].squeeze(-1),\n",
    "        sequence_lengths,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4453b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"base_model_with_everything_corrected.csv\", usecols=[\"prompt\", \"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244abe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mpad_token \n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6957a6d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(\n\u001b[1;32m      2\u001b[0m     text\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      3\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      4\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m,\n\u001b[1;32m      7\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(\n",
    "    text=df[\"prompt\"].tolist(),\n",
    "    text_pair=df[\"response\"].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=2048,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "283ab1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def process_rewards_rowwise(df, model, tokenizer, max_length=2048):\n",
    "    reward_scores = []\n",
    "    sequence_lengths = []\n",
    "    reward_logits_list = []\n",
    "\n",
    "    model_device = next(model.parameters()).device  # get model device\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        prompt = row[\"prompt\"]\n",
    "        response = row[\"response\"]\n",
    "\n",
    "        # Tokenize prompt + response pair\n",
    "        tokenized = tokenizer(\n",
    "            text=prompt,\n",
    "            text_pair=response,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"].to(model_device)\n",
    "\n",
    "        # Tokenize prompt alone to get context length\n",
    "        prompt_tokenized = tokenizer(\n",
    "            prompt,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        context_length = prompt_tokenized[\"input_ids\"].size(1)  # prompt token length\n",
    "\n",
    "        # Call get_reward (input_ids shape: [1, seq_len])\n",
    "        reward_logits, scores, sequence_length = get_reward(\n",
    "            model,\n",
    "            input_ids,\n",
    "            tokenizer.pad_token_id,\n",
    "            context_length\n",
    "        )\n",
    "\n",
    "        # Store outputs as scalars or lists\n",
    "        reward_scores.append(scores.item())\n",
    "        sequence_lengths.append(sequence_length.item())\n",
    "        reward_logits_list.append(reward_logits.squeeze(0).detach().cpu().tolist())  # full logits per token\n",
    "\n",
    "    # Add columns to DataFrame\n",
    "    df[\"reward_score\"] = reward_scores\n",
    "    df[\"sequence_length\"] = sequence_lengths\n",
    "    df[\"reward_logits\"] = reward_logits_list\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cda12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_rewards_rowwise(df, trained_value_model_id, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f588bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"reward_score\": \"RM_reward_score\", \"reward_logits\" : \"RM_tokenwise_rewards\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb8e6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"base_model_with_RM_details\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcc6c8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...</td>\n",
       "      <td>Talked to some guy online, he sent me a Snapc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...</td>\n",
       "      <td>My 11 year old, recently deceased friend won'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...</td>\n",
       "      <td>A month long friend and I were texting, and b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...</td>\n",
       "      <td>I tripped while going to my grandadas funeral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...</td>\n",
       "      <td>found out my wife (now wife) had an affair wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...</td>\n",
       "      <td>I couldn't Pee, I was an asshole that day eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...</td>\n",
       "      <td>GF lost her job and is unable to find a new o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...</td>\n",
       "      <td>My friend, severely depressed, refuses to see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...</td>\n",
       "      <td>Wife hates wedding photos, does not like them...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...</td>\n",
       "      <td>I found porn on his \"legal\" tablet, he doesn'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...   \n",
       "1   SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...   \n",
       "2   SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...   \n",
       "3   SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...   \n",
       "4   SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...   \n",
       "..                                                ...   \n",
       "95  SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...   \n",
       "96  SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...   \n",
       "97  SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...   \n",
       "98  SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...   \n",
       "99  SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...   \n",
       "\n",
       "                                             response  \n",
       "0    Talked to some guy online, he sent me a Snapc...  \n",
       "1    My 11 year old, recently deceased friend won'...  \n",
       "2    A month long friend and I were texting, and b...  \n",
       "3    I tripped while going to my grandadas funeral...  \n",
       "4    found out my wife (now wife) had an affair wi...  \n",
       "..                                                ...  \n",
       "95   I couldn't Pee, I was an asshole that day eve...  \n",
       "96   GF lost her job and is unable to find a new o...  \n",
       "97   My friend, severely depressed, refuses to see...  \n",
       "98   Wife hates wedding photos, does not like them...  \n",
       "99   I found porn on his \"legal\" tablet, he doesn'...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c5ecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"base_model_with_RM_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c3f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>RM_reward_score</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>RM_tokenwise_rewards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...</td>\n",
       "      <td>Talked to some guy online, he sent me a Snapc...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>0.561722</td>\n",
       "      <td>544</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...</td>\n",
       "      <td>My 11 year old, recently deceased friend won'...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 1585...</td>\n",
       "      <td>0.730876</td>\n",
       "      <td>323</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...</td>\n",
       "      <td>A month long friend and I were texting, and b...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>1.547613</td>\n",
       "      <td>234</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...</td>\n",
       "      <td>I tripped while going to my grandadas funeral...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...</td>\n",
       "      <td>0.761009</td>\n",
       "      <td>398</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...</td>\n",
       "      <td>found out my wife (now wife) had an affair wi...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>1.390531</td>\n",
       "      <td>245</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...</td>\n",
       "      <td>I couldn't Pee, I was an asshole that day eve...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...</td>\n",
       "      <td>0.759217</td>\n",
       "      <td>472</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...</td>\n",
       "      <td>GF lost her job and is unable to find a new o...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>417</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...</td>\n",
       "      <td>My friend, severely depressed, refuses to see...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2727...</td>\n",
       "      <td>0.913609</td>\n",
       "      <td>454</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...</td>\n",
       "      <td>Wife hates wedding photos, does not like them...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>0.763344</td>\n",
       "      <td>470</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...</td>\n",
       "      <td>I found porn on his \"legal\" tablet, he doesn'...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>1.420595</td>\n",
       "      <td>437</td>\n",
       "      <td>[[0.16722245514392853], [0.6319139003753662], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...   \n",
       "1   SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...   \n",
       "2   SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...   \n",
       "3   SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...   \n",
       "4   SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...   \n",
       "..                                                ...   \n",
       "95  SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...   \n",
       "96  SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...   \n",
       "97  SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...   \n",
       "98  SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...   \n",
       "99  SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...   \n",
       "\n",
       "                                             response  \\\n",
       "0    Talked to some guy online, he sent me a Snapc...   \n",
       "1    My 11 year old, recently deceased friend won'...   \n",
       "2    A month long friend and I were texting, and b...   \n",
       "3    I tripped while going to my grandadas funeral...   \n",
       "4    found out my wife (now wife) had an affair wi...   \n",
       "..                                                ...   \n",
       "95   I couldn't Pee, I was an asshole that day eve...   \n",
       "96   GF lost her job and is unable to find a new o...   \n",
       "97   My friend, severely depressed, refuses to see...   \n",
       "98   Wife hates wedding photos, does not like them...   \n",
       "99   I found porn on his \"legal\" tablet, he doesn'...   \n",
       "\n",
       "                                            input_ids  RM_reward_score  \\\n",
       "0   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         0.561722   \n",
       "1   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 1585...         0.730876   \n",
       "2   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         1.547613   \n",
       "3   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...         0.761009   \n",
       "4   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         1.390531   \n",
       "..                                                ...              ...   \n",
       "95  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...         0.759217   \n",
       "96  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         0.903624   \n",
       "97  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2727...         0.913609   \n",
       "98  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         0.763344   \n",
       "99  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         1.420595   \n",
       "\n",
       "    sequence_length                               RM_tokenwise_rewards  \n",
       "0               544  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "1               323  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "2               234  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "3               398  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "4               245  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "..              ...                                                ...  \n",
       "95              472  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "96              417  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "97              454  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "98              470  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "99              437  [[0.16722245514392853], [0.6319139003753662], ...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b692048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"RM_tokenwise_rewards\" : \"RM_tokenwise_values\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424a227",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4b009fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def parse_tokenwise_value(row, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Parses a single string of RM_tokenwise_values from a DataFrame row.\n",
    "    Returns a 1D tensor of floats.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nested_list = ast.literal_eval(row)  # [[x], [y], ...]\n",
    "        flat_list = [x[0] for x in nested_list]\n",
    "        return torch.tensor(flat_list, device=device)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error parsing row: {row[:100]}...\") from e\n",
    "\n",
    "def parse_tokenwise_column(df, column=\"RM_tokenwise_values\", device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Applies the parse_tokenwise_value function to the entire column.\n",
    "    Returns a new Series of tensors.\n",
    "    \"\"\"\n",
    "    return df[column].apply(lambda row: parse_tokenwise_value(row, device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9489150",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = parse_tokenwise_column(df)\n",
    "df[\"RM_tokenwise_values\"] = new_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c57d19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_sum_tokenwise_values(value):\n",
    "    \"\"\"\n",
    "    Handles both raw string and already-parsed tensor formats.\n",
    "    \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            nested_list = ast.literal_eval(value)  # [[x], [y], ...]\n",
    "            flat_list = [x[0] for x in nested_list]\n",
    "            return sum(flat_list)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to parse string row: {value[:100]}...\") from e\n",
    "\n",
    "    elif isinstance(value, torch.Tensor):\n",
    "        return value.sum().item()\n",
    "\n",
    "    elif isinstance(value, list):  # in case it's a list of floats already\n",
    "        return sum(value)\n",
    "\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected type for RM_tokenwise_values: {type(value)}\")\n",
    "\n",
    "\n",
    "def add_tokenwise_sum_column(df, source_col=\"RM_tokenwise_values\", new_col=\"RM_tokenwise_sum\"):\n",
    "    \"\"\"\n",
    "    Adds a new column with the sum of tokenwise values per row.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[source_col].apply(safe_sum_tokenwise_values)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b55c0f",
   "metadata": {},
   "source": [
    "### verifying RM tokenwise values are different, even thought first few values look the same in all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>RM_reward_score</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>RM_tokenwise_values</th>\n",
       "      <th>RM_tokenwise_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...</td>\n",
       "      <td>Talked to some guy online, he sent me a Snapc...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>0.561722</td>\n",
       "      <td>544</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1172.383057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...</td>\n",
       "      <td>My 11 year old, recently deceased friend won'...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 1585...</td>\n",
       "      <td>0.730876</td>\n",
       "      <td>323</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1611.715820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...</td>\n",
       "      <td>A month long friend and I were texting, and b...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>1.547613</td>\n",
       "      <td>234</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>3149.649658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...</td>\n",
       "      <td>I tripped while going to my grandadas funeral...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...</td>\n",
       "      <td>0.761009</td>\n",
       "      <td>398</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1671.090332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...</td>\n",
       "      <td>found out my wife (now wife) had an affair wi...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>1.390531</td>\n",
       "      <td>245</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2826.423340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...</td>\n",
       "      <td>I couldn't Pee, I was an asshole that day eve...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...</td>\n",
       "      <td>0.759217</td>\n",
       "      <td>472</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1531.397705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...</td>\n",
       "      <td>GF lost her job and is unable to find a new o...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>417</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2054.581055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...</td>\n",
       "      <td>My friend, severely depressed, refuses to see...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2727...</td>\n",
       "      <td>0.913609</td>\n",
       "      <td>454</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2052.542725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...</td>\n",
       "      <td>Wife hates wedding photos, does not like them...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>0.763344</td>\n",
       "      <td>470</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1662.169678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...</td>\n",
       "      <td>I found porn on his \"legal\" tablet, he doesn'...</td>\n",
       "      <td>[6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...</td>\n",
       "      <td>1.420595</td>\n",
       "      <td>437</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2715.549072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...   \n",
       "1   SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...   \n",
       "2   SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...   \n",
       "3   SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...   \n",
       "4   SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...   \n",
       "..                                                ...   \n",
       "95  SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...   \n",
       "96  SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...   \n",
       "97  SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...   \n",
       "98  SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...   \n",
       "99  SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...   \n",
       "\n",
       "                                             response  \\\n",
       "0    Talked to some guy online, he sent me a Snapc...   \n",
       "1    My 11 year old, recently deceased friend won'...   \n",
       "2    A month long friend and I were texting, and b...   \n",
       "3    I tripped while going to my grandadas funeral...   \n",
       "4    found out my wife (now wife) had an affair wi...   \n",
       "..                                                ...   \n",
       "95   I couldn't Pee, I was an asshole that day eve...   \n",
       "96   GF lost her job and is unable to find a new o...   \n",
       "97   My friend, severely depressed, refuses to see...   \n",
       "98   Wife hates wedding photos, does not like them...   \n",
       "99   I found porn on his \"legal\" tablet, he doesn'...   \n",
       "\n",
       "                                            input_ids  RM_reward_score  \\\n",
       "0   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         0.561722   \n",
       "1   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 1585...         0.730876   \n",
       "2   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         1.547613   \n",
       "3   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...         0.761009   \n",
       "4   [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         1.390531   \n",
       "..                                                ...              ...   \n",
       "95  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 4016...         0.759217   \n",
       "96  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         0.903624   \n",
       "97  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2727...         0.913609   \n",
       "98  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         0.763344   \n",
       "99  [6971, 7941, 1703, 37, 1433, 27, 391, 16, 2284...         1.420595   \n",
       "\n",
       "    sequence_length                                RM_tokenwise_values  \\\n",
       "0               544  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "1               323  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "2               234  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "3               398  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "4               245  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "..              ...                                                ...   \n",
       "95              472  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "96              417  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "97              454  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "98              470  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "99              437  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "\n",
       "    RM_tokenwise_sum  \n",
       "0        1172.383057  \n",
       "1        1611.715820  \n",
       "2        3149.649658  \n",
       "3        1671.090332  \n",
       "4        2826.423340  \n",
       "..               ...  \n",
       "95       1531.397705  \n",
       "96       2054.581055  \n",
       "97       2052.542725  \n",
       "98       1662.169678  \n",
       "99       2715.549072  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_tokenwise_sum_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "031bdc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae_and_returns(df, gamma=1.0, lam=0.95):\n",
    "    \"\"\"\n",
    "    Computes GAE, TD errors, and returns from a DataFrame containing\n",
    "    'RM_tokenwise_values' and 'RM_reward_score'.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with required columns\n",
    "    - gamma: discount factor\n",
    "    - lam: GAE lambda parameter\n",
    "\n",
    "    Returns:\n",
    "    - advantages: torch.Tensor [batch_size, seq_len]\n",
    "    - td_errors: torch.Tensor [batch_size, seq_len]\n",
    "    - returns: torch.Tensor [batch_size, seq_len]\n",
    "    \"\"\"\n",
    "    values = torch.stack(df['RM_tokenwise_values'].tolist())  # [B, T]\n",
    "    rewards = torch.zeros_like(values)\n",
    "    for i, score in enumerate(df['RM_reward_score']):\n",
    "        rewards[i, -1] = score  # reward only at the last token\n",
    "\n",
    "    batch_size, seq_len = values.shape\n",
    "    advantages_reversed = []\n",
    "    td_errors_reversed = []\n",
    "    lastgaelam = torch.zeros(batch_size, device=values.device)\n",
    "\n",
    "    for t in reversed(range(seq_len)):\n",
    "        nextvalues = values[:, t + 1] if t < seq_len - 1 else 0.0\n",
    "        delta = rewards[:, t] + gamma * nextvalues - values[:, t]\n",
    "        td_errors_reversed.append(delta)\n",
    "        lastgaelam = delta + gamma * lam * lastgaelam\n",
    "        advantages_reversed.append(lastgaelam)\n",
    "\n",
    "    advantages = torch.stack(advantages_reversed[::-1], dim=1)\n",
    "    td_errors = torch.stack(td_errors_reversed[::-1], dim=1)\n",
    "    returns = advantages + values\n",
    "    return advantages, td_errors, returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ecd1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "advantages, td_errors, returns = compute_gae_and_returns(df)\n",
    "df[\"RM_advantages\"] = advantages.tolist()\n",
    "df[\"RM_td_errors\"] = td_errors.tolist()\n",
    "df[\"RM_returns\"] = returns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db8e921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_x_value_model_id =  \"10x_lr_20k/value_model\"\n",
    "hun_x_value_model_id =  \"100x_lr_20k/value_model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cd421c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_x_value_model = AutoModelForSequenceClassification.from_pretrained(ten_x_value_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f27a492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_x_value_model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40a26899",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_critic_backbone = getattr(ten_x_value_model, ten_x_value_model.base_model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb3dc137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>RM_reward_score</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>RM_tokenwise_values</th>\n",
       "      <th>RM_tokenwise_sum</th>\n",
       "      <th>RM_advantages</th>\n",
       "      <th>RM_td_errors</th>\n",
       "      <th>RM_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...</td>\n",
       "      <td>Talked to some guy online, he sent me a Snapc...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.561722</td>\n",
       "      <td>544</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1172.383057</td>\n",
       "      <td>[0.7460709810256958, 0.29618895053863525, 0.32...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[0.9132934212684631, 0.9281028509140015, 0.944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...</td>\n",
       "      <td>My 11 year old, recently deceased friend won'...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.730876</td>\n",
       "      <td>323</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1611.715820</td>\n",
       "      <td>[0.8514430522918701, 0.4071069359779358, 0.437...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0186655521392822, 1.0390207767486572, 1.060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...</td>\n",
       "      <td>A month long friend and I were texting, and b...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.547613</td>\n",
       "      <td>234</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>3149.649658</td>\n",
       "      <td>[1.0517261028289795, 0.6179311871528625, 0.659...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.2189486026763916, 1.249845027923584, 1.2828...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...</td>\n",
       "      <td>I tripped while going to my grandadas funeral...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.761009</td>\n",
       "      <td>398</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1671.090332</td>\n",
       "      <td>[0.8933334946632385, 0.4512021541595459, 0.483...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0605559349060059, 1.083116054534912, 1.1073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...</td>\n",
       "      <td>found out my wife (now wife) had an affair wi...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.390531</td>\n",
       "      <td>245</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2826.423340</td>\n",
       "      <td>[0.8885331153869629, 0.44614914059638977, 0.47...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.055755615234375, 1.0780630111694336, 1.1019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...</td>\n",
       "      <td>I couldn't Pee, I was an asshole that day eve...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.759217</td>\n",
       "      <td>472</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1531.397705</td>\n",
       "      <td>[0.9096167087554932, 0.4683423638343811, 0.501...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0768392086029053, 1.1002562046051025, 1.125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...</td>\n",
       "      <td>GF lost her job and is unable to find a new o...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>417</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2054.581055</td>\n",
       "      <td>[0.9705684781074524, 0.5325021147727966, 0.569...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.1377909183502197, 1.1644160747528076, 1.192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...</td>\n",
       "      <td>My friend, severely depressed, refuses to see...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.913609</td>\n",
       "      <td>454</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2052.542725</td>\n",
       "      <td>[0.9002393484115601, 0.45847150683403015, 0.49...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0674618482589722, 1.0903854370117188, 1.114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...</td>\n",
       "      <td>Wife hates wedding photos, does not like them...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.763344</td>\n",
       "      <td>470</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1662.169678</td>\n",
       "      <td>[1.0358400344848633, 0.6012091040611267, 0.641...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.2030625343322754, 1.2331230640411377, 1.265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...</td>\n",
       "      <td>I found porn on his \"legal\" tablet, he doesn'...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.420595</td>\n",
       "      <td>437</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2715.549072</td>\n",
       "      <td>[0.8044341802597046, 0.3576239049434662, 0.385...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[0.9716566205024719, 0.9895378351211548, 1.008...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...   \n",
       "1   SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...   \n",
       "2   SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...   \n",
       "3   SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...   \n",
       "4   SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...   \n",
       "..                                                ...   \n",
       "95  SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...   \n",
       "96  SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...   \n",
       "97  SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...   \n",
       "98  SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...   \n",
       "99  SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...   \n",
       "\n",
       "                                             response  \\\n",
       "0    Talked to some guy online, he sent me a Snapc...   \n",
       "1    My 11 year old, recently deceased friend won'...   \n",
       "2    A month long friend and I were texting, and b...   \n",
       "3    I tripped while going to my grandadas funeral...   \n",
       "4    found out my wife (now wife) had an affair wi...   \n",
       "..                                                ...   \n",
       "95   I couldn't Pee, I was an asshole that day eve...   \n",
       "96   GF lost her job and is unable to find a new o...   \n",
       "97   My friend, severely depressed, refuses to see...   \n",
       "98   Wife hates wedding photos, does not like them...   \n",
       "99   I found porn on his \"legal\" tablet, he doesn'...   \n",
       "\n",
       "                                            input_ids  RM_reward_score  \\\n",
       "0   [tensor(6971), tensor(7941), tensor(1703), ten...         0.561722   \n",
       "1   [tensor(6971), tensor(7941), tensor(1703), ten...         0.730876   \n",
       "2   [tensor(6971), tensor(7941), tensor(1703), ten...         1.547613   \n",
       "3   [tensor(6971), tensor(7941), tensor(1703), ten...         0.761009   \n",
       "4   [tensor(6971), tensor(7941), tensor(1703), ten...         1.390531   \n",
       "..                                                ...              ...   \n",
       "95  [tensor(6971), tensor(7941), tensor(1703), ten...         0.759217   \n",
       "96  [tensor(6971), tensor(7941), tensor(1703), ten...         0.903624   \n",
       "97  [tensor(6971), tensor(7941), tensor(1703), ten...         0.913609   \n",
       "98  [tensor(6971), tensor(7941), tensor(1703), ten...         0.763344   \n",
       "99  [tensor(6971), tensor(7941), tensor(1703), ten...         1.420595   \n",
       "\n",
       "    sequence_length                                RM_tokenwise_values  \\\n",
       "0               544  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "1               323  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "2               234  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "3               398  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "4               245  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "..              ...                                                ...   \n",
       "95              472  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "96              417  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "97              454  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "98              470  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "99              437  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "\n",
       "    RM_tokenwise_sum                                      RM_advantages  \\\n",
       "0        1172.383057  [0.7460709810256958, 0.29618895053863525, 0.32...   \n",
       "1        1611.715820  [0.8514430522918701, 0.4071069359779358, 0.437...   \n",
       "2        3149.649658  [1.0517261028289795, 0.6179311871528625, 0.659...   \n",
       "3        1671.090332  [0.8933334946632385, 0.4512021541595459, 0.483...   \n",
       "4        2826.423340  [0.8885331153869629, 0.44614914059638977, 0.47...   \n",
       "..               ...                                                ...   \n",
       "95       1531.397705  [0.9096167087554932, 0.4683423638343811, 0.501...   \n",
       "96       2054.581055  [0.9705684781074524, 0.5325021147727966, 0.569...   \n",
       "97       2052.542725  [0.9002393484115601, 0.45847150683403015, 0.49...   \n",
       "98       1662.169678  [1.0358400344848633, 0.6012091040611267, 0.641...   \n",
       "99       2715.549072  [0.8044341802597046, 0.3576239049434662, 0.385...   \n",
       "\n",
       "                                         RM_td_errors  \\\n",
       "0   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "1   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "2   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "3   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "4   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "..                                                ...   \n",
       "95  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "96  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "97  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "98  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "99  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "\n",
       "                                           RM_returns  \n",
       "0   [0.9132934212684631, 0.9281028509140015, 0.944...  \n",
       "1   [1.0186655521392822, 1.0390207767486572, 1.060...  \n",
       "2   [1.2189486026763916, 1.249845027923584, 1.2828...  \n",
       "3   [1.0605559349060059, 1.083116054534912, 1.1073...  \n",
       "4   [1.055755615234375, 1.0780630111694336, 1.1019...  \n",
       "..                                                ...  \n",
       "95  [1.0768392086029053, 1.1002562046051025, 1.125...  \n",
       "96  [1.1377909183502197, 1.1644160747528076, 1.192...  \n",
       "97  [1.0674618482589722, 1.0903854370117188, 1.114...  \n",
       "98  [1.2030625343322754, 1.2331230640411377, 1.265...  \n",
       "99  [0.9716566205024719, 0.9895378351211548, 1.008...  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_input_ids_column_to_lists(df, column=\"input_ids\"):\n",
    "    \"\"\"\n",
    "    Convert a string column of input_ids like '[1, 2, 3]' into actual Python lists of ints.\n",
    "    \"\"\"\n",
    "    df[column] = df[column].apply(ast.literal_eval)\n",
    "    return df\n",
    "\n",
    "def convert_input_ids_to_tensors(df, column=\"input_ids\"):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame column of input_ids from list of ints to torch.Tensor.\n",
    "    \"\"\"\n",
    "    df[column] = df[column].apply(lambda x: torch.tensor(x, dtype=torch.long))\n",
    "    return df\n",
    "\n",
    "\n",
    "parse_input_ids_column_to_lists(df)\n",
    "convert_input_ids_to_tensors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecdbfb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_critic_backbone.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5466b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f320a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_per_token_values_from_prompt_response(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    value_model,\n",
    "    prompt_col=\"prompt\",\n",
    "    response_col=\"response\",\n",
    "    new_col=\"VF_pred_value\",\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns per-token value predictions from value_model.score(hidden_states).\n",
    "    Stores the list of values (1 per token) in a new DataFrame column.\n",
    "    \"\"\"\n",
    "    value_model.eval()\n",
    "    value_model.to(device)\n",
    "    critic_backbone = getattr(value_model, value_model.base_model_prefix)\n",
    "\n",
    "    all_token_values = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Scoring tokens\"):\n",
    "        text = row[prompt_col] + row[response_col]\n",
    "        encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        input_ids = encoded[\"input_ids\"].to(device)\n",
    "        attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = critic_backbone(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            hidden_states = output.hidden_states[-1]  # [1, seq_len, hidden_dim]\n",
    "            value_logits = value_model.score(hidden_states).squeeze(0).squeeze(-1)  # [seq_len]\n",
    "\n",
    "        all_token_values.append(value_logits.detach().cpu().tolist())\n",
    "\n",
    "    df[new_col] = all_token_values\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02d4ef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring tokens: 100%|██████████| 100/100 [00:08<00:00, 12.47it/s]\n"
     ]
    }
   ],
   "source": [
    "df = get_per_token_values_from_prompt_response(df, tokenizer, ten_x_value_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af8e2040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 2048, 2048)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"VF_pred_value\"][0]), len(df[\"RM_returns\"][0]), len(df[\"RM_tokenwise_values\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fb74f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>RM_reward_score</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>RM_tokenwise_values</th>\n",
       "      <th>RM_tokenwise_sum</th>\n",
       "      <th>RM_advantages</th>\n",
       "      <th>RM_td_errors</th>\n",
       "      <th>RM_returns</th>\n",
       "      <th>VF_pred_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...</td>\n",
       "      <td>Talked to some guy online, he sent me a Snapc...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.561722</td>\n",
       "      <td>544</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1172.383057</td>\n",
       "      <td>[0.7460709810256958, 0.29618895053863525, 0.32...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[0.9132934212684631, 0.9281028509140015, 0.944...</td>\n",
       "      <td>[3.5257740020751953, 3.05199933052063, 3.61255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...</td>\n",
       "      <td>My 11 year old, recently deceased friend won'...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.730876</td>\n",
       "      <td>323</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1611.715820</td>\n",
       "      <td>[0.8514430522918701, 0.4071069359779358, 0.437...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0186655521392822, 1.0390207767486572, 1.060...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...</td>\n",
       "      <td>A month long friend and I were texting, and b...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.547613</td>\n",
       "      <td>234</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>3149.649658</td>\n",
       "      <td>[1.0517261028289795, 0.6179311871528625, 0.659...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.2189486026763916, 1.249845027923584, 1.2828...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...</td>\n",
       "      <td>I tripped while going to my grandadas funeral...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.761009</td>\n",
       "      <td>398</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1671.090332</td>\n",
       "      <td>[0.8933334946632385, 0.4512021541595459, 0.483...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0605559349060059, 1.083116054534912, 1.1073...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...</td>\n",
       "      <td>found out my wife (now wife) had an affair wi...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.390531</td>\n",
       "      <td>245</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2826.423340</td>\n",
       "      <td>[0.8885331153869629, 0.44614914059638977, 0.47...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.055755615234375, 1.0780630111694336, 1.1019...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...</td>\n",
       "      <td>I couldn't Pee, I was an asshole that day eve...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.759217</td>\n",
       "      <td>472</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1531.397705</td>\n",
       "      <td>[0.9096167087554932, 0.4683423638343811, 0.501...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0768392086029053, 1.1002562046051025, 1.125...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...</td>\n",
       "      <td>GF lost her job and is unable to find a new o...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>417</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2054.581055</td>\n",
       "      <td>[0.9705684781074524, 0.5325021147727966, 0.569...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.1377909183502197, 1.1644160747528076, 1.192...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...</td>\n",
       "      <td>My friend, severely depressed, refuses to see...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.913609</td>\n",
       "      <td>454</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2052.542725</td>\n",
       "      <td>[0.9002393484115601, 0.45847150683403015, 0.49...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0674618482589722, 1.0903854370117188, 1.114...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...</td>\n",
       "      <td>Wife hates wedding photos, does not like them...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.763344</td>\n",
       "      <td>470</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1662.169678</td>\n",
       "      <td>[1.0358400344848633, 0.6012091040611267, 0.641...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.2030625343322754, 1.2331230640411377, 1.265...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...</td>\n",
       "      <td>I found porn on his \"legal\" tablet, he doesn'...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.420595</td>\n",
       "      <td>437</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2715.549072</td>\n",
       "      <td>[0.8044341802597046, 0.3576239049434662, 0.385...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[0.9716566205024719, 0.9895378351211548, 1.008...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...   \n",
       "1   SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...   \n",
       "2   SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...   \n",
       "3   SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...   \n",
       "4   SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...   \n",
       "..                                                ...   \n",
       "95  SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...   \n",
       "96  SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...   \n",
       "97  SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...   \n",
       "98  SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...   \n",
       "99  SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...   \n",
       "\n",
       "                                             response  \\\n",
       "0    Talked to some guy online, he sent me a Snapc...   \n",
       "1    My 11 year old, recently deceased friend won'...   \n",
       "2    A month long friend and I were texting, and b...   \n",
       "3    I tripped while going to my grandadas funeral...   \n",
       "4    found out my wife (now wife) had an affair wi...   \n",
       "..                                                ...   \n",
       "95   I couldn't Pee, I was an asshole that day eve...   \n",
       "96   GF lost her job and is unable to find a new o...   \n",
       "97   My friend, severely depressed, refuses to see...   \n",
       "98   Wife hates wedding photos, does not like them...   \n",
       "99   I found porn on his \"legal\" tablet, he doesn'...   \n",
       "\n",
       "                                            input_ids  RM_reward_score  \\\n",
       "0   [tensor(6971), tensor(7941), tensor(1703), ten...         0.561722   \n",
       "1   [tensor(6971), tensor(7941), tensor(1703), ten...         0.730876   \n",
       "2   [tensor(6971), tensor(7941), tensor(1703), ten...         1.547613   \n",
       "3   [tensor(6971), tensor(7941), tensor(1703), ten...         0.761009   \n",
       "4   [tensor(6971), tensor(7941), tensor(1703), ten...         1.390531   \n",
       "..                                                ...              ...   \n",
       "95  [tensor(6971), tensor(7941), tensor(1703), ten...         0.759217   \n",
       "96  [tensor(6971), tensor(7941), tensor(1703), ten...         0.903624   \n",
       "97  [tensor(6971), tensor(7941), tensor(1703), ten...         0.913609   \n",
       "98  [tensor(6971), tensor(7941), tensor(1703), ten...         0.763344   \n",
       "99  [tensor(6971), tensor(7941), tensor(1703), ten...         1.420595   \n",
       "\n",
       "    sequence_length                                RM_tokenwise_values  \\\n",
       "0               544  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "1               323  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "2               234  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "3               398  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "4               245  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "..              ...                                                ...   \n",
       "95              472  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "96              417  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "97              454  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "98              470  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "99              437  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "\n",
       "    RM_tokenwise_sum                                      RM_advantages  \\\n",
       "0        1172.383057  [0.7460709810256958, 0.29618895053863525, 0.32...   \n",
       "1        1611.715820  [0.8514430522918701, 0.4071069359779358, 0.437...   \n",
       "2        3149.649658  [1.0517261028289795, 0.6179311871528625, 0.659...   \n",
       "3        1671.090332  [0.8933334946632385, 0.4512021541595459, 0.483...   \n",
       "4        2826.423340  [0.8885331153869629, 0.44614914059638977, 0.47...   \n",
       "..               ...                                                ...   \n",
       "95       1531.397705  [0.9096167087554932, 0.4683423638343811, 0.501...   \n",
       "96       2054.581055  [0.9705684781074524, 0.5325021147727966, 0.569...   \n",
       "97       2052.542725  [0.9002393484115601, 0.45847150683403015, 0.49...   \n",
       "98       1662.169678  [1.0358400344848633, 0.6012091040611267, 0.641...   \n",
       "99       2715.549072  [0.8044341802597046, 0.3576239049434662, 0.385...   \n",
       "\n",
       "                                         RM_td_errors  \\\n",
       "0   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "1   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "2   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "3   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "4   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "..                                                ...   \n",
       "95  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "96  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "97  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "98  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "99  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "\n",
       "                                           RM_returns  \\\n",
       "0   [0.9132934212684631, 0.9281028509140015, 0.944...   \n",
       "1   [1.0186655521392822, 1.0390207767486572, 1.060...   \n",
       "2   [1.2189486026763916, 1.249845027923584, 1.2828...   \n",
       "3   [1.0605559349060059, 1.083116054534912, 1.1073...   \n",
       "4   [1.055755615234375, 1.0780630111694336, 1.1019...   \n",
       "..                                                ...   \n",
       "95  [1.0768392086029053, 1.1002562046051025, 1.125...   \n",
       "96  [1.1377909183502197, 1.1644160747528076, 1.192...   \n",
       "97  [1.0674618482589722, 1.0903854370117188, 1.114...   \n",
       "98  [1.2030625343322754, 1.2331230640411377, 1.265...   \n",
       "99  [0.9716566205024719, 0.9895378351211548, 1.008...   \n",
       "\n",
       "                                        VF_pred_value  \n",
       "0   [3.5257740020751953, 3.05199933052063, 3.61255...  \n",
       "1   [3.5257749557495117, 3.051999568939209, 3.6125...  \n",
       "2   [3.5257749557495117, 3.051999807357788, 3.6125...  \n",
       "3   [3.5257749557495117, 3.051999807357788, 3.6125...  \n",
       "4   [3.5257749557495117, 3.051999807357788, 3.6125...  \n",
       "..                                                ...  \n",
       "95  [3.5257749557495117, 3.051999568939209, 3.6125...  \n",
       "96  [3.5257749557495117, 3.051999807357788, 3.6125...  \n",
       "97  [3.5257749557495117, 3.051999568939209, 3.6125...  \n",
       "98  [3.5257749557495117, 3.051999568939209, 3.6125...  \n",
       "99  [3.5257749557495117, 3.051999807357788, 3.6125...  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a270fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_value_loss_mse(df, vf_col=\"VF_pred_value\", rm_col=\"RM_returns\", new_col=\"value_loss\"):\n",
    "    losses = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        vf_pred = torch.tensor(row[vf_col], dtype=torch.float32)\n",
    "        rm_return = torch.tensor(row[rm_col], dtype=torch.float32)[:len(vf_pred)]\n",
    "\n",
    "        # Compute MSE loss\n",
    "        loss = F.mse_loss(vf_pred, rm_return, reduction=\"mean\").item()\n",
    "        losses.append(loss)\n",
    "\n",
    "    df[new_col] = losses\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4910053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = compute_value_loss_mse(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8a5d777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>RM_reward_score</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>RM_tokenwise_values</th>\n",
       "      <th>RM_tokenwise_sum</th>\n",
       "      <th>RM_advantages</th>\n",
       "      <th>RM_td_errors</th>\n",
       "      <th>RM_returns</th>\n",
       "      <th>VF_pred_value</th>\n",
       "      <th>value_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...</td>\n",
       "      <td>Talked to some guy online, he sent me a Snapc...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.561722</td>\n",
       "      <td>544</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1172.383057</td>\n",
       "      <td>[0.7460709810256958, 0.29618895053863525, 0.32...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[0.9132934212684631, 0.9281028509140015, 0.944...</td>\n",
       "      <td>[3.5257740020751953, 3.05199933052063, 3.61255...</td>\n",
       "      <td>0.333823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...</td>\n",
       "      <td>My 11 year old, recently deceased friend won'...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.730876</td>\n",
       "      <td>323</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1611.715820</td>\n",
       "      <td>[0.8514430522918701, 0.4071069359779358, 0.437...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0186655521392822, 1.0390207767486572, 1.060...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "      <td>0.269458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...</td>\n",
       "      <td>A month long friend and I were texting, and b...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.547613</td>\n",
       "      <td>234</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>3149.649658</td>\n",
       "      <td>[1.0517261028289795, 0.6179311871528625, 0.659...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.2189486026763916, 1.249845027923584, 1.2828...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "      <td>0.419698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...</td>\n",
       "      <td>I tripped while going to my grandadas funeral...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.761009</td>\n",
       "      <td>398</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1671.090332</td>\n",
       "      <td>[0.8933334946632385, 0.4512021541595459, 0.483...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0605559349060059, 1.083116054534912, 1.1073...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "      <td>0.355657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...</td>\n",
       "      <td>found out my wife (now wife) had an affair wi...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.390531</td>\n",
       "      <td>245</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2826.423340</td>\n",
       "      <td>[0.8885331153869629, 0.44614914059638977, 0.47...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.055755615234375, 1.0780630111694336, 1.1019...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "      <td>0.173714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...</td>\n",
       "      <td>I couldn't Pee, I was an asshole that day eve...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.759217</td>\n",
       "      <td>472</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1531.397705</td>\n",
       "      <td>[0.9096167087554932, 0.4683423638343811, 0.501...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0768392086029053, 1.1002562046051025, 1.125...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "      <td>0.409522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...</td>\n",
       "      <td>GF lost her job and is unable to find a new o...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.903624</td>\n",
       "      <td>417</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2054.581055</td>\n",
       "      <td>[0.9705684781074524, 0.5325021147727966, 0.569...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.1377909183502197, 1.1644160747528076, 1.192...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "      <td>0.142988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...</td>\n",
       "      <td>My friend, severely depressed, refuses to see...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.913609</td>\n",
       "      <td>454</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2052.542725</td>\n",
       "      <td>[0.9002393484115601, 0.45847150683403015, 0.49...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.0674618482589722, 1.0903854370117188, 1.114...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "      <td>0.542371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...</td>\n",
       "      <td>Wife hates wedding photos, does not like them...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>0.763344</td>\n",
       "      <td>470</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>1662.169678</td>\n",
       "      <td>[1.0358400344848633, 0.6012091040611267, 0.641...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[1.2030625343322754, 1.2331230640411377, 1.265...</td>\n",
       "      <td>[3.5257749557495117, 3.051999568939209, 3.6125...</td>\n",
       "      <td>0.158014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...</td>\n",
       "      <td>I found porn on his \"legal\" tablet, he doesn'...</td>\n",
       "      <td>[tensor(6971), tensor(7941), tensor(1703), ten...</td>\n",
       "      <td>1.420595</td>\n",
       "      <td>437</td>\n",
       "      <td>[tensor(0.1672), tensor(0.6319), tensor(0.6234...</td>\n",
       "      <td>2715.549072</td>\n",
       "      <td>[0.8044341802597046, 0.3576239049434662, 0.385...</td>\n",
       "      <td>[0.4646914601325989, -0.008473753929138184, 0....</td>\n",
       "      <td>[0.9716566205024719, 0.9895378351211548, 1.008...</td>\n",
       "      <td>[3.5257749557495117, 3.051999807357788, 3.6125...</td>\n",
       "      <td>0.394099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   SUBREDDIT: r/relationships\\n\\nTITLE: Me [19 F]...   \n",
       "1   SUBREDDIT: r/Parenting\\n\\nTITLE: My 11 year ol...   \n",
       "2   SUBREDDIT: r/relationships\\n\\nTITLE: The girl ...   \n",
       "3   SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by accidently...   \n",
       "4   SUBREDDIT: r/relationships\\n\\nTITLE: I [32 M] ...   \n",
       "..                                                ...   \n",
       "95  SUBREDDIT: r/tifu\\n\\nTITLE: TIFU by inviting t...   \n",
       "96  SUBREDDIT: r/relationships\\n\\nTITLE: My GF [25...   \n",
       "97  SUBREDDIT: r/offmychest\\n\\nTITLE: I am sick an...   \n",
       "98  SUBREDDIT: r/relationships\\n\\nTITLE: Help, ple...   \n",
       "99  SUBREDDIT: r/relationships\\n\\nTITLE: (21F) Fou...   \n",
       "\n",
       "                                             response  \\\n",
       "0    Talked to some guy online, he sent me a Snapc...   \n",
       "1    My 11 year old, recently deceased friend won'...   \n",
       "2    A month long friend and I were texting, and b...   \n",
       "3    I tripped while going to my grandadas funeral...   \n",
       "4    found out my wife (now wife) had an affair wi...   \n",
       "..                                                ...   \n",
       "95   I couldn't Pee, I was an asshole that day eve...   \n",
       "96   GF lost her job and is unable to find a new o...   \n",
       "97   My friend, severely depressed, refuses to see...   \n",
       "98   Wife hates wedding photos, does not like them...   \n",
       "99   I found porn on his \"legal\" tablet, he doesn'...   \n",
       "\n",
       "                                            input_ids  RM_reward_score  \\\n",
       "0   [tensor(6971), tensor(7941), tensor(1703), ten...         0.561722   \n",
       "1   [tensor(6971), tensor(7941), tensor(1703), ten...         0.730876   \n",
       "2   [tensor(6971), tensor(7941), tensor(1703), ten...         1.547613   \n",
       "3   [tensor(6971), tensor(7941), tensor(1703), ten...         0.761009   \n",
       "4   [tensor(6971), tensor(7941), tensor(1703), ten...         1.390531   \n",
       "..                                                ...              ...   \n",
       "95  [tensor(6971), tensor(7941), tensor(1703), ten...         0.759217   \n",
       "96  [tensor(6971), tensor(7941), tensor(1703), ten...         0.903624   \n",
       "97  [tensor(6971), tensor(7941), tensor(1703), ten...         0.913609   \n",
       "98  [tensor(6971), tensor(7941), tensor(1703), ten...         0.763344   \n",
       "99  [tensor(6971), tensor(7941), tensor(1703), ten...         1.420595   \n",
       "\n",
       "    sequence_length                                RM_tokenwise_values  \\\n",
       "0               544  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "1               323  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "2               234  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "3               398  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "4               245  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "..              ...                                                ...   \n",
       "95              472  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "96              417  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "97              454  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "98              470  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "99              437  [tensor(0.1672), tensor(0.6319), tensor(0.6234...   \n",
       "\n",
       "    RM_tokenwise_sum                                      RM_advantages  \\\n",
       "0        1172.383057  [0.7460709810256958, 0.29618895053863525, 0.32...   \n",
       "1        1611.715820  [0.8514430522918701, 0.4071069359779358, 0.437...   \n",
       "2        3149.649658  [1.0517261028289795, 0.6179311871528625, 0.659...   \n",
       "3        1671.090332  [0.8933334946632385, 0.4512021541595459, 0.483...   \n",
       "4        2826.423340  [0.8885331153869629, 0.44614914059638977, 0.47...   \n",
       "..               ...                                                ...   \n",
       "95       1531.397705  [0.9096167087554932, 0.4683423638343811, 0.501...   \n",
       "96       2054.581055  [0.9705684781074524, 0.5325021147727966, 0.569...   \n",
       "97       2052.542725  [0.9002393484115601, 0.45847150683403015, 0.49...   \n",
       "98       1662.169678  [1.0358400344848633, 0.6012091040611267, 0.641...   \n",
       "99       2715.549072  [0.8044341802597046, 0.3576239049434662, 0.385...   \n",
       "\n",
       "                                         RM_td_errors  \\\n",
       "0   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "1   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "2   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "3   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "4   [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "..                                                ...   \n",
       "95  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "96  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "97  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "98  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "99  [0.4646914601325989, -0.008473753929138184, 0....   \n",
       "\n",
       "                                           RM_returns  \\\n",
       "0   [0.9132934212684631, 0.9281028509140015, 0.944...   \n",
       "1   [1.0186655521392822, 1.0390207767486572, 1.060...   \n",
       "2   [1.2189486026763916, 1.249845027923584, 1.2828...   \n",
       "3   [1.0605559349060059, 1.083116054534912, 1.1073...   \n",
       "4   [1.055755615234375, 1.0780630111694336, 1.1019...   \n",
       "..                                                ...   \n",
       "95  [1.0768392086029053, 1.1002562046051025, 1.125...   \n",
       "96  [1.1377909183502197, 1.1644160747528076, 1.192...   \n",
       "97  [1.0674618482589722, 1.0903854370117188, 1.114...   \n",
       "98  [1.2030625343322754, 1.2331230640411377, 1.265...   \n",
       "99  [0.9716566205024719, 0.9895378351211548, 1.008...   \n",
       "\n",
       "                                        VF_pred_value  value_loss  \n",
       "0   [3.5257740020751953, 3.05199933052063, 3.61255...    0.333823  \n",
       "1   [3.5257749557495117, 3.051999568939209, 3.6125...    0.269458  \n",
       "2   [3.5257749557495117, 3.051999807357788, 3.6125...    0.419698  \n",
       "3   [3.5257749557495117, 3.051999807357788, 3.6125...    0.355657  \n",
       "4   [3.5257749557495117, 3.051999807357788, 3.6125...    0.173714  \n",
       "..                                                ...         ...  \n",
       "95  [3.5257749557495117, 3.051999568939209, 3.6125...    0.409522  \n",
       "96  [3.5257749557495117, 3.051999807357788, 3.6125...    0.142988  \n",
       "97  [3.5257749557495117, 3.051999568939209, 3.6125...    0.542371  \n",
       "98  [3.5257749557495117, 3.051999568939209, 3.6125...    0.158014  \n",
       "99  [3.5257749557495117, 3.051999807357788, 3.6125...    0.394099  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02424389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ten_lr_td_value_eval.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loading_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
